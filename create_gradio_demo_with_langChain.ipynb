{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all your libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.faiss import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTDFAQ.csv not found in current directory\n",
      "UTDFAQ.csv not found in current directory\n",
      "UTDFAQ.csv not found in current directory\n",
      "UTDFAQ.csv not found in current directory\n",
      "UTDFAQ.csv not found in current directory\n",
      "UTDFAQ.csv not found in current directory\n",
      "UTDFAQ.csv not found in current directory\n",
      "UTDFAQ.csv not found in current directory\n",
      "UTDFAQ.csv not found in current directory\n",
      "UTDFAQ.csv not found in current directory\n",
      "UTDFAQ.csv not found in current directory\n",
      "UTDFAQ.csv not found in current directory\n",
      "UTDFAQ.csv not found in current directory\n",
      "UTDFAQ.csv not found in current directory\n",
      "UTDFAQ.csv not found in current directory\n",
      "UTDFAQ.csv not found in current directory\n",
      "UTDFAQ.csv not found in current directory\n",
      "UTDFAQ.csv not found in current directory\n",
      "UTDFAQ.csv not found in current directory\n",
      "UTDFAQ.csv not found in current directory\n",
      "UTDFAQ.csv not found in current directory\n",
      "UTDFAQ.csv not found in current directory\n",
      "UTDFAQ.csv not found in current directory\n",
      "UTDFAQ.csv not found in current directory\n",
      "UTDFAQ.csv not found in current directory\n",
      "FAQ Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "faq = None\n",
    "for path in os.listdir():\n",
    "    if path == \"UTDFAQ.csv\":\n",
    "        faq = path\n",
    "    else:\n",
    "        print(\"UTDFAQ.csv not found in current directory\")\n",
    "        faq = \"FAQ Dataset.csv\"\n",
    "print(faq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Unable to find '/Users/ari/Desktop/UTD-chat-bot/FAQ Dataset.csv' at /Users/ari/Desktop/UTD-chat-bot",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3v/x7y9n99d1h31tndwyn13s0yh0000gn/T/ipykernel_48168/1279538404.py\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrich\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m faq_dataset = load_dataset(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \"csv\", data_files=faq)\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaq_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aiml/lib/python3.9/site-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, num_proc, **config_kwargs)\u001b[0m\n\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;31m# Create a dataset builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m     builder_instance = load_dataset_builder(\n\u001b[0m\u001b[1;32m   1736\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aiml/lib/python3.9/site-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, use_auth_token, **config_kwargs)\u001b[0m\n\u001b[1;32m   1491\u001b[0m         \u001b[0mdownload_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdownload_config\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mDownloadConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m         \u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_auth_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_auth_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1493\u001b[0;31m     dataset_module = dataset_module_factory(\n\u001b[0m\u001b[1;32m   1494\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m         \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aiml/lib/python3.9/site-packages/datasets/load.py\u001b[0m in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m     \u001b[0;31m# Try packaged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_PACKAGED_DATASETS_MODULES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m         return PackagedDatasetModuleFactory(\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m             \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aiml/lib/python3.9/site-packages/datasets/load.py\u001b[0m in \u001b[0;36mget_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m             \u001b[0msanitize_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_files\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_files\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mget_data_patterns_locally\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         )\n\u001b[0;32m--> 708\u001b[0;31m         data_files = DataFilesDict.from_local_or_remote(\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mpatterns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aiml/lib/python3.9/site-packages/datasets/data_files.py\u001b[0m in \u001b[0;36mfrom_local_or_remote\u001b[0;34m(cls, patterns, base_path, allowed_extensions, use_auth_token)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatterns_for_key\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m             out[key] = (\n\u001b[0;32m--> 796\u001b[0;31m                 DataFilesList.from_local_or_remote(\n\u001b[0m\u001b[1;32m    797\u001b[0m                     \u001b[0mpatterns_for_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                     \u001b[0mbase_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aiml/lib/python3.9/site-packages/datasets/data_files.py\u001b[0m in \u001b[0;36mfrom_local_or_remote\u001b[0;34m(cls, patterns, base_path, allowed_extensions, use_auth_token)\u001b[0m\n\u001b[1;32m    762\u001b[0m     ) -> \"DataFilesList\":\n\u001b[1;32m    763\u001b[0m         \u001b[0mbase_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_path\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbase_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresolve_patterns_locally_or_by_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_extensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0morigin_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_origin_metadata_locally_or_by_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aiml/lib/python3.9/site-packages/datasets/data_files.py\u001b[0m in \u001b[0;36mresolve_patterns_locally_or_by_urls\u001b[0;34m(base_path, patterns, allowed_extensions)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0mdata_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_resolve_single_pattern_locally\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_extensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m                 \u001b[0mdata_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aiml/lib/python3.9/site-packages/datasets/data_files.py\u001b[0m in \u001b[0;36m_resolve_single_pattern_locally\u001b[0;34m(base_path, pattern, allowed_extensions)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mallowed_extensions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0merror_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\" with any supported extension {list(allowed_extensions)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Unable to find '/Users/ari/Desktop/UTD-chat-bot/FAQ Dataset.csv' at /Users/ari/Desktop/UTD-chat-bot"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from rich import print\n",
    "from rich import print\n",
    "\n",
    "faq_dataset = load_dataset(\n",
    "    \"csv\", data_files=faq)\n",
    "print(faq_dataset)\n",
    "## remove all the None values\n",
    "faq_dataset = faq_dataset.filter(lambda x: x['Question'] is not None and x['Answering'] is not None)\n",
    "## reaplace all the word ARC to AccessAbility Resource Center and\n",
    "'''\n",
    "Office location: Administration Building, Room 2.224\n",
    "Email: studentaccess@utdallas.edu (Do not email attachments, upload documents to utd.link/arcupload only.)\n",
    "Phone: (972) 883-2098\n",
    "Fax: Please don’t fax, use utd.link/arcupload\n",
    "Mail: AD 30, 800 West Campbell Rd., Richardson TX 75080\n",
    "'''\n",
    "faq_dataset = faq_dataset.map(lambda x: {'Question': x['Question'].replace('ARC', 'AccessAbility Resource Center'), 'Answering': x['Answering'].replace('ARC', 'AccessAbility Resource Center')})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove all the None values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove all the None values\n",
    "faq_dataset = faq_dataset.filter(lambda x: x['Question'] is not None and x['Answering'] is not None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace all the ARC to Accessible Resource Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all the word UTD to University of Texas at Dallas\n",
    "# replace all the ARC to AccessAbility Resource Center\n",
    "faq_dataset = faq_dataset.map(lambda x: {'Question': x['Question'].replace('UTD', 'University of Texas at Dallas'), 'Answering': x['Answering'].replace('UTD', 'University of Texas at Dallas')})\n",
    "faq_dataset = faq_dataset.map(lambda x: {'Question': x['Question'].replace('ARC', 'AccessAbility Resource Center'), 'Answering': x['Answering'].replace('ARC', 'AccessAbility Resource Center')})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Open AI Emebddigns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "\n",
    "OPENKEY_API = os.getenv(\"OPENAI_KEY\")\n",
    "\n",
    "#ORGANIZATION_ID = os.getenv(\"ORGANIZATION_ID\")\n",
    "#openai.organization = ORGANIZATION_ID\n",
    "# get this from top-right dropdown on OpenAI under organization > settings\n",
    "openai.api_key = OPENKEY_API\n",
    "# get API key from top-right dropdown on OpenAI website\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENKEY_API\n",
    "openai.Engine.list()  # check we have authenticated\n",
    "print(openai.Engine.list())\n",
    "## model of choices\n",
    "MODEL = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ini the Pinecone Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "PINECONE_APIKEY = os.getenv(\"PINECONE_APIKEY\")\n",
    "if PINECONE_APIKEY is None:\n",
    "    raise Exception(\"PINECONE_API_KEY not found in environment variables add the Pinecone API key to the .env file\")\n",
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "pinecone.init(\n",
    "    api_key = PINECONE_APIKEY,\n",
    "    environment=\"us-east-1-aws\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_env():\n",
    "    #setting up OpenAI Api\n",
    "    OPENKEY_API = os.getenv(\"OPENAI_KEY\")\n",
    "    ORGANIZATION_ID = os.getenv(\"ORGANIZATION_ID\")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = OPENKEY_API\n",
    "    openai.organization = ORGANIZATION_ID\n",
    "    # get this from top-right dropdown on OpenAI under organization > settings\n",
    "    openai.api_key = OPENKEY_API\n",
    "    # get API key from top-right dropdown on OpenAI website\n",
    "\n",
    "    openai.Engine.list()  # check we have authenticated\n",
    "\n",
    "    #setting pup pinecon\n",
    "    PINECONE_APIKEY = os.getenv(\"PINECONE_APIKEY\")\n",
    "    # initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "    pinecone.init(\n",
    "        api_key = PINECONE_APIKEY ,\n",
    "        environment=\"us-east1-gcp\" , \n",
    "    )\n",
    "    assert len(pinecone.list_indexes()) > 0, \"No indexes found in your Pinecone account. Please create an index and try again.\"\n",
    "\n",
    "    print(pinecone.list_indexes())\n",
    "    if pinecone.list_indexes()[0] != \"utd-chatbot\":\n",
    "        print(\"Please create an index named 'utd-chatbot\")\n",
    "\n",
    "\n",
    "    print(f'The list of pinecone index {pinecone.list_indexes()}')\n",
    "    if pinecone.list_indexes()[0] != \"utd-chatbot\":\n",
    "        print(\"Please create an index named 'utd-chatbot\")\n",
    "\n",
    "    ## I the name of the vector database\n",
    "    return  pinecone.Index(index_name = pinecone.list_indexes()[0]) , pinecone.list_indexes()[0] , pinecone.describe_index(pinecone.list_indexes()[0])\n",
    "\n",
    "pinecone_index , index_name , index_description = set_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Role Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_prompt = \"\"\"\n",
    "Please act as a University of Texas at Dallas Counselor. I will provide you with an individual \n",
    "looking for guidance at the University of Texas at Dallas, and your task is to help them \n",
    "solve their problem\\n\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(ans):\n",
    "    if \"ARC\" in ans:\n",
    "        ans = ans.replace(\"ARC\", \"AccessAbility Resource Center\")\n",
    "        ans += \"\"\" \n",
    "        Office location: Administration Building, Room 2.224 \\n\n",
    "        Email: studentaccess@utdallas.edu (Do not email attachments, upload documents to utd.link/arcupload only.) \\n\n",
    "        Phone: (972) 883-2098 \\n\n",
    "        Fax: Please don’t fax, use utd.link/arcupload \\n\n",
    "        Mail: AD 30, 800 West Campbell Rd., Richardson TX 75080    Office location: Administration Building, Room 2.224\\n\n",
    "        \"\"\"\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.pinecone import Pinecone\n",
    "\n",
    "def query_vector_database(query):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    # vectorstore = Pinecone.from_documents(documents, embeddings, index_name=INDEX_NAME) # only used for initial index creation, upserts document embeddings as well as the documents themselves\n",
    "    vectorstore = Pinecone( pinecone_index, embeddings.embed_query, \"text\") # use this for subsequent runs\n",
    "\n",
    "    docs = vectorstore.similarity_search_with_score(query)\n",
    "\n",
    "    res = []\n",
    "    for doc in docs:\n",
    "      answer = faq_dataset['train'].filter(lambda x: x['Question'] == doc[0].page_content) # get row with the corresponding question in query\n",
    "      print(answer)\n",
    "      res.append({\"Question\": f\"{answer['Question'][0]}\", \"Answer\": f\"{answer['Answering'][0]}\", \"URL\": f\"{answer['URL'][0]}\"}) # adds a dictionary of the row to list\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = Pinecone( pinecone_index, embeddings.embed_query, \"text\") # use this for subsequent runs\n",
    "docs = vectorstore.similarity_search_with_score(\"I have ADHD and I need help with my classes.\")\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "def create_an_standard_qa_prompt(res):\n",
    "    example_prompt = PromptTemplate(\n",
    "        input_variables=[\"Question\", \"Answer\", \"URL\"], \n",
    "        template=\"Question: {Question}\\n{Answer}\\nSource:{URL}\"\n",
    "    )\n",
    "\n",
    "    fewShotPrompt = FewShotPromptTemplate(\n",
    "        examples=res,\n",
    "        example_prompt=example_prompt,\n",
    "        suffix=\"Question: {input}\",\n",
    "        input_variables=[\"input\"]\n",
    "    )\n",
    "\n",
    "    system_message_prompt = SystemMessage(content=role_prompt)\n",
    "    human_message_prompt = HumanMessagePromptTemplate(prompt=fewShotPrompt)\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "    type(chat_prompt)\n",
    "    return chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "\n",
    "def called_llm_decoder_model(query, prompt):\n",
    "  chain = LLMChain(llm=chat, prompt=prompt)\n",
    "  output = chain.run(input=query)\n",
    "  return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chathistory = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import csv\n",
    "questions = []\n",
    "answers = []\n",
    "import random\n",
    "random_value = random.randint(0, 1000)\n",
    "\n",
    "def utd_chatbot( question ):\n",
    "    ## store the question in the csvs file\n",
    "    #print(question)\n",
    "    res = query_vector_database(question)\n",
    "    #print(res)\n",
    "    propmt = create_an_standard_qa_prompt(res)\n",
    "    #print(propmt)\n",
    "    ans = called_llm_decoder_model(question, propmt)\n",
    "    # post_process(ans)\n",
    "    chathistory.append({ans, question})\n",
    "    return chathistory, ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lauch of Gradio\n",
    "demo = gr.Interface(fn=utd_chatbot, inputs=\"text\", outputs=[\"text\", \"text\"], title = \"UTD-Chatbot\")\n",
    "demo.launch( share = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the a demo\n",
    "#demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Language Chain to Generate one Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "I want you to act as a naming consultant for new companies.\n",
    "\n",
    "Here are some examples of good company names:\n",
    "\n",
    "- search engine, Google\n",
    "- social media, Facebook\n",
    "- video sharing, YouTube\n",
    "\n",
    "The name should be short, catchy and easy to remember.\n",
    "\n",
    "What is a good name for a company that makes {product}?\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", n=2, best_of=2)\n",
    "from rich import print\n",
    "print( llm(\"Tell me about yourself\") ) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.16 ('utd_chatbot')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9ff9b4d34df2539584901dcbbee8740b4a40a3636c7400fd1d2b55da32052e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
